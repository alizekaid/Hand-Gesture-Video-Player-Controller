\documentclass[12pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{fancyhdr}
\usepackage{hyperref}
\usepackage{titlesec}

% Page Setup
\geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
}

% Header and Footer
\pagestyle{fancy}
\fancyhf{}
\rhead{HCI Project Proposal}
\lhead{Touchless Gesture Control}
\cfoot{\thepage}

% Title Info
\title{\textbf{Project Proposal: Touchless Gesture Control Interface for Media Playback}}
\author{Ali Zekaid (Example Author)}
\date{\today}

\begin{document}

\maketitle

\section{Topic Selection and Approval}

\textbf{Topic:} Touchless Gesture Control Interface for Media Playback

\subsection*{Justification for Class Forum}
I propose designing a \textbf{Touchless Gesture Control Interface} that allows users to control media playback (such as music or video) using hand gestures captured by a webcam.

\subsection*{Relevance to HCI}
This project explores \textbf{Natural User Interfaces (NUI)} by replacing traditional mechanical input devices (mouse, keyboard) with computer vision-based interaction. It addresses key HCI concepts such as:
\begin{itemize}
    \item \textbf{Accessibility:} For users with limited mobility.
    \item \textbf{Ergonomics:} Reducing repetitive strain.
    \item \textbf{Intuitive Mapping:} Direct mapping of physical gestures to digital actions.
\end{itemize}
The system will focus on providing immediate visual feedback to ensure a smooth user experience, which is a core principle of effective interaction design.

\section{Initial Project Description}

\subsection{Project Objective}
The objective is to design and implement a desktop application that enables users to control system media volume and playback status without physical contact. The system aims to provide a reliable, low-latency interaction method suitable for scenarios where touching devices is inconvenient (e.g., cooking, dirty hands) or impossible.

\subsection{Test Field: Online Players}
The primary test field for this application will be \textbf{Online Video Players} (specifically YouTube). The application will simulate keyboard shortcuts (e.g., 'k' for Pause, Arrow keys for Volume) to interface directly with the browser-based player, allowing users to control web content seamlessly.

\subsection{Input/Output Specification}
\begin{itemize}
    \item \textbf{Input:}
    \begin{itemize}
        \item Video stream from a standard laptop webcam (RGB data).
        \item Hand landmarks and gesture recognition data (coordinates of finger joints).
    \end{itemize}
    \item \textbf{Output:}
    \begin{itemize}
        \item \textbf{System Actions:} Media control commands sending simulated keyboard events (Play/Pause, Volume Up/Down).
        \item \textbf{Visual Feedback:} A GUI overlay on the video feed showing the detected gesture, confidence level, and triggered action (e.g., "Volume Up" text appearing when the user gestures).
    \end{itemize}
\end{itemize}

\subsection{Planned Functionality}
\begin{enumerate}
    \item \textbf{Hand Detection \& Tracking:} Real-time tracking of hand landmarks using Google's \texttt{MediaPipe}.
    \item \textbf{Gesture Recognition:} Implementing logic to classify states such as:
    \begin{itemize}
        \item \textit{Open Palm} $\rightarrow$ Play
        \item \textit{Closed Fist} $\rightarrow$ Pause (or toggle)
        \item \textit{L-Shape / Reverse L-Shape} (Volume Mode) + \textit{Vertical Movement} $\rightarrow$ Volume Up/Down
        \item \textit{Pinch} (within Volume Mode) $\rightarrow$ Mute Toggle
    \end{itemize}
    \item \textbf{Interaction Smoothing:} Algorithms to prevent "jitter" or accidental repeated commands (debouncing and state tracking).
    \item \textbf{GUI Mode:} A window displaying the camera feed with overlaid skeleton tracking and status indicators.
\end{enumerate}

\section{Tools and Environment}
\begin{itemize}
    \item \textbf{Programming Language:} Python 3.x
    \item \textbf{Libraries/Frameworks:}
    \begin{itemize}
        \item \textbf{OpenCV:} For image processing and video capture.
        \item \textbf{MediaPipe:} For efficient, pre-trained hand tracking and landmark detection.
        \item \textbf{PyAutoGUI:} To interface with the operating system and simulate key presses.
        \item \textbf{NumPy:} For vector calculations.
    \end{itemize}
    \item \textbf{Hardware:} Standard USB Webcam or built-in Laptop Camera.
\end{itemize}

\section{Constraints and Assumptions}
\begin{itemize}
    \item \textbf{Lighting:} The system assumes a reasonably well-lit environment for the camera to detect hands.
    \item \textbf{Single User:} The system is designed to track gestures from a single primary user to avoid conflicting commands.
    \item \textbf{Camera Position:} Assumes the user is sitting within 0.5 to 1.0 meters of the camera.
    \item \textbf{Performance:} Must run at a minimum of 15 FPS to ensure the interaction feels responsive.
\end{itemize}

\end{document}
